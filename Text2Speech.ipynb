{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text2Speech.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPAlv_IdEJ_l"
      },
      "source": [
        "# Text2Speech\r\n",
        "This notebook provide a demonstration of the realtime E2E-TTS using ESPnet-TTS and ParallelWaveGAN (+ MelGAN)\r\n",
        "\r\n",
        "  * ESPnet: https://github.com/espnet/espnet\r\n",
        "  * ParallelWaveGAN: https://github.com/kan-bayashi/ParallelWaveGAN\r\n",
        "\r\n",
        "Author: Hesam Tavakoli ([1nj3ct0r](https://github.com/1nj3ct0rrr/))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mu_qejSGr09"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF4BZEyiGyYf"
      },
      "source": [
        "# Install minimal components\r\n",
        "\r\n",
        "!pip install -q parallel_wavegan PyYaml unidecode ConfigArgparse g2p_en espnet_tts_frontend\r\n",
        "\r\n",
        "!git clone -q https://github.com/espnet/espnet.git\r\n",
        "!cd espnet && git fetch && git checkout -b v.0.9.1 refs/tags/v.0.9.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KRpY--6HHAn"
      },
      "source": [
        "## Download Pretrained Feature Generation Model\r\n",
        "You can select one from three models. Please only run the selected model cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4FRKvNuO7LV"
      },
      "source": [
        "### (A) Tacotron 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmUNPM94O_GO"
      },
      "source": [
        "# Download pretrained model\r\n",
        "import os\r\n",
        "if not os.path.exists(\"downloads/en/tacotron2\"):\r\n",
        "    !./espnet/utils/download_from_google_drive.sh \\\r\n",
        "        https://drive.google.com/open?id=1lFfeyewyOsxaNO-DEWy9iSz6qB9ZS1UR downloads/en/tacotron2 tar.gz\r\n",
        "\r\n",
        "# Set path\r\n",
        "trans_type = \"phn\"\r\n",
        "dict_path = \"downloads/en/tacotron2/data/lang_1phn/phn_train_no_dev_units.txt\"\r\n",
        "model_path = \"downloads/en/tacotron2/exp/phn_train_no_dev_pytorch_train_pytorch_tacotron2.v3/results/model.last1.avg.best\"\r\n",
        "\r\n",
        "print(\"Sucessfully Finished Download...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI9Ye3inPYUF"
      },
      "source": [
        "### (B) Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlNmbvspPcPd"
      },
      "source": [
        "# Download pretrained model\r\n",
        "import os\r\n",
        "if not os.path.exists(\"downloads/en/transformer\"):\r\n",
        "    !./espnet/utils/download_from_google_drive.sh \\\r\n",
        "        https://drive.google.com/open?id=1z8KSOWVBjK-_Ws4RxVN4NTx-Buy03-7c downloads/en/transformer tar.gz\r\n",
        "\r\n",
        "# Set path\r\n",
        "trans_type = \"phn\"\r\n",
        "dict_path = \"downloads/en/transformer/data/lang_1phn/phn_train_no_dev_units.txt\"\r\n",
        "model_path = \"downloads/en/transformer/exp/phn_train_no_dev_pytorch_train_pytorch_transformer.v3.single/results/model.last1.avg.best\"\r\n",
        "\r\n",
        "print(\"Sucessfully Finished Download...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe0jU9zRPtYo"
      },
      "source": [
        "### (C) Fast Speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F9hX-SvPkb-"
      },
      "source": [
        "# Download pretrained model\r\n",
        "import os\r\n",
        "if not os.path.exists(\"downloads/en/fastspeech\"):\r\n",
        "    !./espnet/utils/download_from_google_drive.sh \\\r\n",
        "        https://drive.google.com/open?id=1P9I4qag8wAcJiTCPawt6WCKBqUfJFtFp downloads/en/fastspeech tar.gz\r\n",
        "\r\n",
        "# Set path\r\n",
        "trans_type = \"phn\"\r\n",
        "dict_path = \"downloads/en/fastspeech/data/lang_1phn/phn_train_no_dev_units.txt\"\r\n",
        "model_path = \"downloads/en/fastspeech/exp/phn_train_no_dev_pytorch_train_tacotron2.v3_fastspeech.v4.single/results/model.last1.avg.best\"\r\n",
        "\r\n",
        "print(\"Sucessfully Finished Download...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4S6JJ9BP-Ah"
      },
      "source": [
        "## Download Prentrained Vocoder Model\r\n",
        "You can select one from two models. Please only run the selected model cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzXRuuDhQRHB"
      },
      "source": [
        "### (A) Parallel WaveGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TbT3pfNQ_E1"
      },
      "source": [
        "# Download pretrained model\r\n",
        "import os\r\n",
        "if not os.path.exists(\"downloads/en/parallel_wavegan\"):\r\n",
        "    !./espnet/utils/download_from_google_drive.sh \\\r\n",
        "        https://drive.google.com/open?id=1Grn7X9wD35UcDJ5F7chwdTqTa4U7DeVB downloads/en/parallel_wavegan tar.gz\r\n",
        "\r\n",
        "# Set path\r\n",
        "vocoder_path = \"downloads/en/parallel_wavegan/ljspeech.parallel_wavegan.v2/checkpoint-400000steps.pkl\"\r\n",
        "\r\n",
        "print(\"Sucessfully Finished Download...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_y1NXlARHkM"
      },
      "source": [
        "### (B) MelGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAQpLQz3SrHf"
      },
      "source": [
        "# Download pretrained model\r\n",
        "import os\r\n",
        "if not os.path.exists(\"downloads/en/melgan\"):\r\n",
        "    !./espnet/utils/download_from_google_drive.sh \\\r\n",
        "        https://drive.google.com/open?id=1_a8faVA5OGCzIcJNw4blQYjfG4oA9VEt downloads/en/melgan tar.gz\r\n",
        "\r\n",
        "# Set path\r\n",
        "vocoder_path = \"downloads/en/melgan/train_nodev_ljspeech_melgan.v3.long/checkpoint-4000000steps.pkl\"\r\n",
        "\r\n",
        "print(\"Sucessfully Finished Download...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH2N4IDPSxNd"
      },
      "source": [
        "### (C) Multi-Band MelGAN\r\n",
        "This is an **Experimental** model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slm2tJrnVd0g"
      },
      "source": [
        "# Download pretrained model\r\n",
        "import os\r\n",
        "if not os.path.exists(\"downloads/en/mb-melgan\"):\r\n",
        "    !./espnet/utils/download_from_google_drive.sh \\\r\n",
        "        https://drive.google.com/open?id=1rGG5y15uy4WZ-lJy8NPVTkmB_6VhC20V downloads/en/mb-melgan tar.gz\r\n",
        "\r\n",
        "# Set path\r\n",
        "vocoder_path = \"downloads/en/mb-melgan/train_nodev_ljspeech_multi_band_melgan.v1/checkpoint-1000000steps.pkl\"\r\n",
        "\r\n",
        "print(\"Sucessfully Finished Download...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOnVAZnqVnWO"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8CJnknFVorZ"
      },
      "source": [
        "# Add path\r\n",
        "import sys\r\n",
        "sys.path.append(\"espnet\")\r\n",
        "\r\n",
        "# Define device\r\n",
        "import torch\r\n",
        "device = torch.device(\"cuda\")\r\n",
        "\r\n",
        "# Define E2E-TTS model\r\n",
        "from argparse import Namespace\r\n",
        "from espnet.asr.asr_utils import get_model_conf\r\n",
        "from espnet.asr.asr_utils import torch_load\r\n",
        "from espnet.utils.dynamic_import import dynamic_import\r\n",
        "idim, odim, train_args = get_model_conf(model_path)\r\n",
        "model_class = dynamic_import(train_args.model_module)\r\n",
        "model = model_class(idim, odim, train_args)\r\n",
        "torch_load(model_path, model)\r\n",
        "model = model.eval().to(device)\r\n",
        "inference_args = Namespace(**{\r\n",
        "    \"threshold\": 0.5,\"minlenratio\": 0.0, \"maxlenratio\": 10.0,\r\n",
        "    # Only for Tacotron 2\r\n",
        "    \"use_attention_constraint\": True, \"backward_window\": 1,\"forward_window\":3,\r\n",
        "    # Only for fastspeech (lower than 1.0 is faster speech, higher than 1.0 is slower speech)\r\n",
        "    \"fastspeech_alpha\": 1.0,\r\n",
        "})\r\n",
        "\r\n",
        "# Define neural vocoder\r\n",
        "from parallel_wavegan.utils import load_model\r\n",
        "fs = 22050\r\n",
        "vocoder = load_model(vocoder_path)\r\n",
        "vocoder.remove_weight_norm()\r\n",
        "vocoder = vocoder.eval().to(device)\r\n",
        "\r\n",
        "# Define text frontend\r\n",
        "from tacotron_cleaner.cleaners import custom_english_cleaners\r\n",
        "from g2p_en import G2p\r\n",
        "with open(dict_path) as f:\r\n",
        "    lines = f.readlines()\r\n",
        "lines = [line.replace(\"\\n\", \"\").split(\" \") for line in lines]\r\n",
        "char_to_id = {c: int(i) for c, i in lines}\r\n",
        "g2p = G2p()\r\n",
        "def frontend(text):\r\n",
        "    \"\"\"Clean text and then convert to id sequence.\"\"\"\r\n",
        "    text = custom_english_cleaners(text)\r\n",
        "    \r\n",
        "    if trans_type == \"phn\":\r\n",
        "        text = filter(lambda s: s != \" \", g2p(text))\r\n",
        "        text = \" \".join(text)\r\n",
        "        print(f\"Cleaned Text: {text}\")\r\n",
        "        charseq = text.split(\" \")\r\n",
        "    else:\r\n",
        "        print(f\"Cleaned Text: {text}\")\r\n",
        "        charseq = list(text)\r\n",
        "    idseq = []\r\n",
        "    for c in charseq:\r\n",
        "        if c.isspace():\r\n",
        "            idseq += [char_to_id[\"<space>\"]]\r\n",
        "        elif c not in char_to_id.keys():\r\n",
        "            idseq += [char_to_id[\"<unk>\"]]\r\n",
        "        else:\r\n",
        "            idseq += [char_to_id[c]]\r\n",
        "    idseq += [idim - 1]  # <eos>\r\n",
        "    return torch.LongTensor(idseq).view(-1).to(device)\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "print(\"Now Ready to Synthesize!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aHyLr4WWAe2"
      },
      "source": [
        "## Synthesis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhe5zQygV71G"
      },
      "source": [
        "import time\r\n",
        "print(\"Input your favorite sentence in English:\")\r\n",
        "input_text = input()\r\n",
        "with torch.no_grad():\r\n",
        "    start = time.time()\r\n",
        "    x = frontend(input_text)\r\n",
        "    c, _, _ = model.inference(x, inference_args)\r\n",
        "    y = vocoder.inference(c)\r\n",
        "rtf = (time.time() - start) / (len(y) / fs)\r\n",
        "print(f\"RTF = {rtf:5f}\")\r\n",
        "\r\n",
        "from IPython.display import display, Audio\r\n",
        "display(Audio(y.view(-1).cpu().numpy(), rate=fs))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}